{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bf00ac",
   "metadata": {},
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e5fae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac9683",
   "metadata": {},
   "source": [
    "## Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a61988f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c6fea",
   "metadata": {},
   "source": [
    "## Uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d50941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emma</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age  Experience\n",
       "0    Alice   25           2\n",
       "1      Bob   30           4\n",
       "2  Charlie   22           7\n",
       "3    David   35          12\n",
       "4     Emma   28           9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the XLSX file\n",
    "df = pd.read_excel('data/names_and_ages.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a32d6",
   "metadata": {},
   "source": [
    "## Reading data with SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efb75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e236e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-MRCQNP2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1bb6d7bbeb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the session with its respective name\n",
    "spark = SparkSession.builder.appName('practice').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204745e",
   "metadata": {},
   "source": [
    "When we execute in our local, we anly work with one cluster. On the other and, working on cloud, we can create multiple cluster and instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483085ec",
   "metadata": {},
   "source": [
    "To see the data in our file, we use the previous session and use the methods according to the PySpark documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7954b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: string, Experience: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = 'data/names_and_ages.csv'\n",
    "spark.read.csv(csv_path, header = True, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a90dbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Experience|\n",
      "+-------+---+----------+\n",
      "|  Alice| 25|         2|\n",
      "|    Bob| 30|         4|\n",
      "|Charlie| 22|         7|\n",
      "|  David| 35|        12|\n",
      "|   Emma| 28|         9|\n",
      "|  Frank| 40|         1|\n",
      "|  Grace| 23|         3|\n",
      "|  Henry| 32|        14|\n",
      "|  Irene| 27|        25|\n",
      "|   Jack| 33|         2|\n",
      "|  Karen| 26|         3|\n",
      "|    Leo| 29|         1|\n",
      "|  Maria| 31|         0|\n",
      "| Nathan| 37|         0|\n",
      "| Olivia| 24|         3|\n",
      "|   Paul| 38|         1|\n",
      "|  Quinn| 21|        14|\n",
      "| Rachel| 34|         3|\n",
      "|    Sam| 39|         6|\n",
      "| Taylor| 36|        15|\n",
      "+-------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_path = 'data/names_and_ages.csv'\n",
    "df_pyspark = spark.read.csv(csv_path, header = True, inferSchema = True ,sep = ';')\n",
    "\n",
    "# To read the information in the dataframe\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f488b",
   "metadata": {},
   "source": [
    "Another way to upload the files, could be using the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f99739b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Experience|\n",
      "+-------+---+----------+\n",
      "|  Alice| 25|         2|\n",
      "|    Bob| 30|         4|\n",
      "|Charlie| 22|         7|\n",
      "|  David| 35|        12|\n",
      "|   Emma| 28|         9|\n",
      "|  Frank| 40|         1|\n",
      "|  Grace| 23|         3|\n",
      "|  Henry| 32|        14|\n",
      "|  Irene| 27|        25|\n",
      "|   Jack| 33|         2|\n",
      "|  Karen| 26|         3|\n",
      "|    Leo| 29|         1|\n",
      "|  Maria| 31|         0|\n",
      "| Nathan| 37|         0|\n",
      "| Olivia| 24|         3|\n",
      "|   Paul| 38|         1|\n",
      "|  Quinn| 21|        14|\n",
      "| Rachel| 34|         3|\n",
      "|    Sam| 39|         6|\n",
      "| Taylor| 36|        15|\n",
      "+-------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Other form to read the information in the dataframe\n",
    "df_pyspark2 = spark.read.option('header', 'true').csv(csv_path, inferSchema = True, sep = ';')\n",
    "\n",
    "# To show the data in the dataframe\n",
    "df_pyspark2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a94f326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see te type\n",
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df12f428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Alice', Age=25, Experience=2),\n",
       " Row(Name='Bob', Age=30, Experience=4),\n",
       " Row(Name='Charlie', Age=22, Experience=7),\n",
       " Row(Name='David', Age=35, Experience=12)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To extract the 4 first rows in the dataframe\n",
    "df_pyspark.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d0dc09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see what is the schema of our dataframe, checking the data types for each column\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49097209",
   "metadata": {},
   "source": [
    "### Selecting columns and indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5782faad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataframe columns \n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4df7b055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "|  Alice|\n",
      "|    Bob|\n",
      "|Charlie|\n",
      "|  David|\n",
      "|   Emma|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To select a column\n",
    "df_pyspark.select('Name').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16eb56d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|   Name|Experience|\n",
      "+-------+----------+\n",
      "|  Alice|         2|\n",
      "|    Bob|         4|\n",
      "|Charlie|         7|\n",
      "|  David|        12|\n",
      "|   Emma|         9|\n",
      "+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To select several columns\n",
    "df_pyspark.select(['Name','Experience']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1452165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check the datatypes\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93cb9f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+-----------------+\n",
      "|summary|   Name|               Age|       Experience|\n",
      "+-------+-------+------------------+-----------------+\n",
      "|  count|     49|                49|               49|\n",
      "|   mean|   NULL|30.897959183673468|7.020408163265306|\n",
      "| stddev|   NULL|6.0904464052289295|6.060424201043904|\n",
      "|    min|  Alice|                20|                0|\n",
      "|    max|Zachary|                45|               25|\n",
      "+-------+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checkout the describe options\n",
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b515143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns\n",
    "df_pyspark = df_pyspark.withColumn('Experience After 3 Years', df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d691075d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------------------------+\n",
      "|   Name|Age|Experience|Experience After 3 Years|\n",
      "+-------+---+----------+------------------------+\n",
      "|  Alice| 25|         2|                       4|\n",
      "|    Bob| 30|         4|                       6|\n",
      "|Charlie| 22|         7|                       9|\n",
      "|  David| 35|        12|                      14|\n",
      "|   Emma| 28|         9|                      11|\n",
      "|  Frank| 40|         1|                       3|\n",
      "|  Grace| 23|         3|                       5|\n",
      "|  Henry| 32|        14|                      16|\n",
      "|  Irene| 27|        25|                      27|\n",
      "|   Jack| 33|         2|                       4|\n",
      "|  Karen| 26|         3|                       5|\n",
      "|    Leo| 29|         1|                       3|\n",
      "|  Maria| 31|         0|                       2|\n",
      "| Nathan| 37|         0|                       2|\n",
      "| Olivia| 24|         3|                       5|\n",
      "|   Paul| 38|         1|                       3|\n",
      "|  Quinn| 21|        14|                      16|\n",
      "| Rachel| 34|         3|                       5|\n",
      "|    Sam| 39|         6|                       8|\n",
      "| Taylor| 36|        15|                      17|\n",
      "+-------+---+----------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To check if the changes were made\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f58fbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "df_pyspark = df_pyspark.drop('Experience After 3 Years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0fe881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Experience|\n",
      "+-------+---+----------+\n",
      "|  Alice| 25|         2|\n",
      "|    Bob| 30|         4|\n",
      "|Charlie| 22|         7|\n",
      "|  David| 35|        12|\n",
      "|   Emma| 28|         9|\n",
      "|  Frank| 40|         1|\n",
      "|  Grace| 23|         3|\n",
      "|  Henry| 32|        14|\n",
      "|  Irene| 27|        25|\n",
      "|   Jack| 33|         2|\n",
      "|  Karen| 26|         3|\n",
      "|    Leo| 29|         1|\n",
      "|  Maria| 31|         0|\n",
      "| Nathan| 37|         0|\n",
      "| Olivia| 24|         3|\n",
      "|   Paul| 38|         1|\n",
      "|  Quinn| 21|        14|\n",
      "| Rachel| 34|         3|\n",
      "|    Sam| 39|         6|\n",
      "| Taylor| 36|        15|\n",
      "+-------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a96ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To rename one column use\n",
    "#df_pyspark = df_pyspark.withColumnRenamed('Name', 'New name')\n",
    "\n",
    "#To rename all the columns use\n",
    "list_columns = df_pyspark.columns\n",
    "list_columns_spanish = ['Nombre' , 'Edad', 'Experiencia']\n",
    "\n",
    "for name, new_name in zip(list_columns , list_columns_spanish):\n",
    "    df_pyspark = df_pyspark.withColumnRenamed(name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1a9dec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----------+\n",
      "| Nombre|Edad|Experiencia|\n",
      "+-------+----+-----------+\n",
      "|  Alice|  25|          2|\n",
      "|    Bob|  30|          4|\n",
      "|Charlie|  22|          7|\n",
      "|  David|  35|         12|\n",
      "|   Emma|  28|          9|\n",
      "|  Frank|  40|          1|\n",
      "|  Grace|  23|          3|\n",
      "|  Henry|  32|         14|\n",
      "|  Irene|  27|         25|\n",
      "|   Jack|  33|          2|\n",
      "|  Karen|  26|          3|\n",
      "|    Leo|  29|          1|\n",
      "|  Maria|  31|          0|\n",
      "| Nathan|  37|          0|\n",
      "| Olivia|  24|          3|\n",
      "|   Paul|  38|          1|\n",
      "|  Quinn|  21|         14|\n",
      "| Rachel|  34|          3|\n",
      "|    Sam|  39|          6|\n",
      "| Taylor|  36|         15|\n",
      "+-------+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
