{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6adebafb",
   "metadata": {},
   "source": [
    "# Groupby and aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba65ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2d014e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-MRCQNP2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>groupby_aggregate_function</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x224d3aae370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('groupby_aggregate_function').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a48bd7",
   "metadata": {},
   "source": [
    "We are going to consider the dataset in https://www.kaggle.com/datasets/varungitboi/employee-salary-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e39aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+--------------+----------------+------+\n",
      "| id|groups|age|healthy_eating|active_lifestyle|salary|\n",
      "+---+------+---+--------------+----------------+------+\n",
      "|  0|     A| 36|             5|               5|  2297|\n",
      "|  1|     A| 55|             3|               5|  1134|\n",
      "|  2|     A| 61|             8|               1|  4969|\n",
      "|  3|     O| 29|             3|               6|   902|\n",
      "|  4|     O| 34|             6|               2|  3574|\n",
      "|  5|     O| 42|             5|               3|  2761|\n",
      "|  6|    AB| 53|             4|               6|  1484|\n",
      "|  7|     B| 41|             8|               6|  3809|\n",
      "|  8|     A| 47|             5|               6|  2065|\n",
      "|  9|     A| 31|             4|               8|  1020|\n",
      "| 10|     A| 47|             6|               9|  1950|\n",
      "| 11|     O| 40|             7|               1|  4387|\n",
      "| 12|     O| 41|             3|               2|  1830|\n",
      "| 13|     O| 46|             6|               8|  2182|\n",
      "| 14|    AB| 51|             7|               5|  3460|\n",
      "| 15|     B| 57|             3|               8|   662|\n",
      "| 16|     A| 33|             3|               5|  1134|\n",
      "| 17|     A| 41|             4|               8|  1020|\n",
      "| 18|     A| 46|             2|               6|   779|\n",
      "| 19|     O| 32|             7|               6|  3228|\n",
      "+---+------+---+--------------+----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('data/employee_data.csv', header = True , inferSchema=True)\n",
    "df_pyspark = df_pyspark.drop('_c0')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bd728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- groups: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- healthy_eating: integer (nullable = true)\n",
      " |-- active_lifestyle: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194a4af",
   "metadata": {},
   "source": [
    "**Groupby and agregate functions works together**. In that way, the `groupBy()` function is used to group the DataFrame rows based on one or more columns, and aggregate functions are used to perform calculations on those grouped data. \n",
    "Aggregate functions allow us to compute summary statistics or derive new columns based on the grouped data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7e95a",
   "metadata": {},
   "source": [
    "We want to know in which group there is the maximum concentration of the salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9e6e73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|groups|sum(salary)|\n",
      "+------+-----------+\n",
      "|     B|     279097|\n",
      "|     O|     849570|\n",
      "|     A|     816083|\n",
      "|    AB|     282711|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Groupby + aggregate function\n",
    "df_pyspark.groupBy('groups').sum('salary').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fec6d0",
   "metadata": {},
   "source": [
    "Now how many people is in each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c0e9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|groups|count|\n",
      "+------+-----+\n",
      "|     B|  125|\n",
      "|     O|  375|\n",
      "|     A|  375|\n",
      "|    AB|  125|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('groups').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed2775",
   "metadata": {},
   "source": [
    "According to the age, in which age we obtain the maximun salary mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb969d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|age|       avg(salary)|\n",
      "+---+------------------+\n",
      "| 31|1892.6521739130435|\n",
      "| 53| 2082.777777777778|\n",
      "| 34|2025.3333333333333|\n",
      "| 28| 2399.153846153846|\n",
      "| 26|2479.2631578947367|\n",
      "| 27|2041.2666666666667|\n",
      "| 44|           2125.24|\n",
      "| 22|            2453.1|\n",
      "| 47|            1727.3|\n",
      "| 52| 2288.823529411765|\n",
      "| 40|            2477.5|\n",
      "| 20|2158.9411764705883|\n",
      "| 57|2068.5714285714284|\n",
      "| 54|2368.3076923076924|\n",
      "| 48|            2244.5|\n",
      "| 19| 2497.590909090909|\n",
      "| 64|          2093.625|\n",
      "| 41|           2412.28|\n",
      "| 43|2006.2272727272727|\n",
      "| 37|2494.0434782608695|\n",
      "+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_avg_salary = df_pyspark.groupBy('age').mean('salary')\n",
    "df_avg_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80fe4735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- avg(salary): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_avg_salary.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25135b4",
   "metadata": {},
   "source": [
    "Using the aggregate function, we can compute the total salary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15008227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|    2227461|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'salary' : 'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954e7d5",
   "metadata": {},
   "source": [
    "Considering the columns `active_lifestyle` we want to know which is the maximum `salary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88a61af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+\n",
      "|active_lifestyle|max(salary)|\n",
      "+----------------+-----------+\n",
      "|               1|       5550|\n",
      "|               6|       4972|\n",
      "|               3|       5086|\n",
      "|               5|       5204|\n",
      "|               9|       4276|\n",
      "|               4|       5435|\n",
      "|               8|       4508|\n",
      "|               7|       4158|\n",
      "|              10|       2881|\n",
      "|               2|       5318|\n",
      "|               0|       4038|\n",
      "+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('active_lifestyle').max('salary').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640611e6",
   "metadata": {},
   "source": [
    "Now, let us consider the minimum `salary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0b4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+\n",
      "|active_lifestyle|min(salary)|\n",
      "+----------------+-----------+\n",
      "|               1|       1481|\n",
      "|               6|        779|\n",
      "|               3|        665|\n",
      "|               5|        553|\n",
      "|               9|        788|\n",
      "|               4|        785|\n",
      "|               8|        662|\n",
      "|               7|        670|\n",
      "|              10|        556|\n",
      "|               2|        667|\n",
      "|               0|       2294|\n",
      "+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('active_lifestyle').min('salary').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6235fe2",
   "metadata": {},
   "source": [
    "According to the `active_lifestyle` we want to know which is the average of salary, so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6352dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|active_lifestyle|       avg(salary)|\n",
      "+----------------+------------------+\n",
      "|               1|3291.6923076923076|\n",
      "|               6|2219.8732394366198|\n",
      "|               3|            2753.0|\n",
      "|               5|2286.2916666666665|\n",
      "|               9|        1684.53125|\n",
      "|               4|2373.1923076923076|\n",
      "|               8|1894.8333333333333|\n",
      "|               7|1951.4110429447853|\n",
      "|              10|1599.1333333333334|\n",
      "|               2|2770.3823529411766|\n",
      "|               0| 3539.714285714286|\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_avg_sal_by_lifestyle = df_pyspark.groupBy('active_lifestyle').avg('salary')\n",
    "df_avg_sal_by_lifestyle.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c35f959b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('active_lifestyle', 'int'), ('avg(salary)', 'double')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_sal_by_lifestyle.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd857a92",
   "metadata": {},
   "source": [
    "If we want to see the `avg(salary)` rounded, we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77502d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+-------------------+\n",
      "|active_lifestyle|       avg(salary)|rounded_avg(salary)|\n",
      "+----------------+------------------+-------------------+\n",
      "|               1|3291.6923076923076|            3291.69|\n",
      "|               6|2219.8732394366198|            2219.87|\n",
      "|               3|            2753.0|             2753.0|\n",
      "|               5|2286.2916666666665|            2286.29|\n",
      "|               9|        1684.53125|            1684.53|\n",
      "|               4|2373.1923076923076|            2373.19|\n",
      "|               8|1894.8333333333333|            1894.83|\n",
      "|               7|1951.4110429447853|            1951.41|\n",
      "|              10|1599.1333333333334|            1599.13|\n",
      "|               2|2770.3823529411766|            2770.38|\n",
      "|               0| 3539.714285714286|            3539.71|\n",
      "+----------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rounded_avg_sal_by_lifestyle = df_avg_sal_by_lifestyle.withColumn(\"rounded_avg(salary)\", round(df_avg_sal_by_lifestyle[\"avg(salary)\"], 2))\n",
    "df_rounded_avg_sal_by_lifestyle.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2a08a",
   "metadata": {},
   "source": [
    "Now, we are going to sort by the column `active_lifestyle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0151e345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+-------------------+\n",
      "|active_lifestyle|       avg(salary)|rounded_avg(salary)|\n",
      "+----------------+------------------+-------------------+\n",
      "|               0| 3539.714285714286|            3539.71|\n",
      "|               1|3291.6923076923076|            3291.69|\n",
      "|               2|2770.3823529411766|            2770.38|\n",
      "|               3|            2753.0|             2753.0|\n",
      "|               4|2373.1923076923076|            2373.19|\n",
      "|               5|2286.2916666666665|            2286.29|\n",
      "|               6|2219.8732394366198|            2219.87|\n",
      "|               7|1951.4110429447853|            1951.41|\n",
      "|               8|1894.8333333333333|            1894.83|\n",
      "|               9|        1684.53125|            1684.53|\n",
      "|              10|1599.1333333333334|            1599.13|\n",
      "+----------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_df_rounded_avg_sal_by_lifestyle = df_rounded_avg_sal_by_lifestyle.orderBy(\"active_lifestyle\")\n",
    "sorted_df_rounded_avg_sal_by_lifestyle.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
