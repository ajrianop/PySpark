{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ecddeb",
   "metadata": {},
   "source": [
    "# Handling with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7afa1a7",
   "metadata": {},
   "source": [
    "Let us read the csv file, with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe4305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Missing_values').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df37b493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+\n",
      "|   Name| Age|Experience|Salary(USD)|\n",
      "+-------+----+----------+-----------+\n",
      "|  Alice|  25|         2|       1882|\n",
      "|    Bob|  30|         4|       6503|\n",
      "|Charlie|  22|         7|       6914|\n",
      "|  David|  35|        12|       8108|\n",
      "|   Emma|  28|         9|       5268|\n",
      "|  Frank|NULL|      NULL|       NULL|\n",
      "|  Grace|  23|         3|       6035|\n",
      "|  Henry|  32|        14|       7443|\n",
      "|  Irene|NULL|        25|       9129|\n",
      "|   Jack|  33|      NULL|       NULL|\n",
      "|  Karen|  26|         3|       6901|\n",
      "|    Leo|  29|         1|       5013|\n",
      "|   NULL|  31|         0|       2893|\n",
      "| Nathan|  37|      NULL|       5647|\n",
      "|   NULL|  24|         3|       7004|\n",
      "|   Paul|  38|         1|       7891|\n",
      "|  Quinn|  21|        14|       8890|\n",
      "| Rachel|  34|         3|       1872|\n",
      "|    Sam|NULL|         6|       4916|\n",
      "| Taylor|  36|      NULL|       5554|\n",
      "+-------+----+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the file with missing values\n",
    "df_pyspark = spark.read.csv('data/names_and_ages_missing_val.csv', header = True , inferSchema = True , sep = ';')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5ddbf",
   "metadata": {},
   "source": [
    "## Using the method .drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280fc30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------+\n",
      "|    Name|Age|Experience|Salary(USD)|\n",
      "+--------+---+----------+-----------+\n",
      "|   Alice| 25|         2|       1882|\n",
      "|     Bob| 30|         4|       6503|\n",
      "| Charlie| 22|         7|       6914|\n",
      "|   David| 35|        12|       8108|\n",
      "|    Emma| 28|         9|       5268|\n",
      "|   Grace| 23|         3|       6035|\n",
      "|   Henry| 32|        14|       7443|\n",
      "|   Karen| 26|         3|       6901|\n",
      "|     Leo| 29|         1|       5013|\n",
      "|    Paul| 38|         1|       7891|\n",
      "|   Quinn| 21|        14|       8890|\n",
      "|  Rachel| 34|         3|       1872|\n",
      "|Victoria| 20|         6|       6827|\n",
      "|  Xander| 28|         2|       7977|\n",
      "| Yasmine| 31|         8|       3342|\n",
      "| Zachary| 29|         2|       5914|\n",
      "|     Ava| 26|         4|       2593|\n",
      "|Benjamin| 32|         3|       9328|\n",
      "|   Chloe| 23|         6|       2089|\n",
      "|  Daniel| 35|        21|       6377|\n",
      "+--------+---+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows with NULL values\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10eaa61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+\n",
      "|   Name| Age|Experience|Salary(USD)|\n",
      "+-------+----+----------+-----------+\n",
      "|  Alice|  25|         2|       1882|\n",
      "|    Bob|  30|         4|       6503|\n",
      "|Charlie|  22|         7|       6914|\n",
      "|  David|  35|        12|       8108|\n",
      "|   Emma|  28|         9|       5268|\n",
      "|  Frank|NULL|      NULL|       NULL|\n",
      "|  Grace|  23|         3|       6035|\n",
      "|  Henry|  32|        14|       7443|\n",
      "|  Irene|NULL|        25|       9129|\n",
      "|   Jack|  33|      NULL|       NULL|\n",
      "|  Karen|  26|         3|       6901|\n",
      "|    Leo|  29|         1|       5013|\n",
      "|   NULL|  31|         0|       2893|\n",
      "| Nathan|  37|      NULL|       5647|\n",
      "|   NULL|  24|         3|       7004|\n",
      "|   Paul|  38|         1|       7891|\n",
      "|  Quinn|  21|        14|       8890|\n",
      "| Rachel|  34|         3|       1872|\n",
      "|    Sam|NULL|         6|       4916|\n",
      "| Taylor|  36|      NULL|       5554|\n",
      "+-------+----+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To drop all the columns which has NULL values in all the line,\n",
    "# but this command doesn't drop the rows with one, two or three null entries\n",
    "# in the same line\n",
    "df_pyspark.na.drop(how = 'all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52347e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------+\n",
      "|    Name|Age|Experience|Salary(USD)|\n",
      "+--------+---+----------+-----------+\n",
      "|   Alice| 25|         2|       1882|\n",
      "|     Bob| 30|         4|       6503|\n",
      "| Charlie| 22|         7|       6914|\n",
      "|   David| 35|        12|       8108|\n",
      "|    Emma| 28|         9|       5268|\n",
      "|   Grace| 23|         3|       6035|\n",
      "|   Henry| 32|        14|       7443|\n",
      "|   Karen| 26|         3|       6901|\n",
      "|     Leo| 29|         1|       5013|\n",
      "|    Paul| 38|         1|       7891|\n",
      "|   Quinn| 21|        14|       8890|\n",
      "|  Rachel| 34|         3|       1872|\n",
      "|Victoria| 20|         6|       6827|\n",
      "|  Xander| 28|         2|       7977|\n",
      "| Yasmine| 31|         8|       3342|\n",
      "| Zachary| 29|         2|       5914|\n",
      "|     Ava| 26|         4|       2593|\n",
      "|Benjamin| 32|         3|       9328|\n",
      "|   Chloe| 23|         6|       2089|\n",
      "|  Daniel| 35|        21|       6377|\n",
      "+--------+---+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To drop all the columns which contains at least one NULL value in the line\n",
    "df_pyspark.na.drop(how = 'any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f68c7289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+\n",
      "|   Name| Age|Experience|Salary(USD)|\n",
      "+-------+----+----------+-----------+\n",
      "|  Alice|  25|         2|       1882|\n",
      "|    Bob|  30|         4|       6503|\n",
      "|Charlie|  22|         7|       6914|\n",
      "|  David|  35|        12|       8108|\n",
      "|   Emma|  28|         9|       5268|\n",
      "|  Frank|NULL|      NULL|       NULL|\n",
      "|  Grace|  23|         3|       6035|\n",
      "|  Henry|  32|        14|       7443|\n",
      "|  Irene|NULL|        25|       9129|\n",
      "|   Jack|  33|      NULL|       NULL|\n",
      "|  Karen|  26|         3|       6901|\n",
      "|    Leo|  29|         1|       5013|\n",
      "|   NULL|  31|         0|       2893|\n",
      "| Nathan|  37|      NULL|       5647|\n",
      "|   NULL|  24|         3|       7004|\n",
      "|   Paul|  38|         1|       7891|\n",
      "|  Quinn|  21|        14|       8890|\n",
      "| Rachel|  34|         3|       1872|\n",
      "|    Sam|NULL|         6|       4916|\n",
      "| Taylor|  36|      NULL|       5554|\n",
      "+-------+----+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold of only ONE null value\n",
    "df_pyspark.na.drop(how = 'any' , thresh = 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78297457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+\n",
      "|   Name| Age|Experience|Salary(USD)|\n",
      "+-------+----+----------+-----------+\n",
      "|  Alice|  25|         2|       1882|\n",
      "|    Bob|  30|         4|       6503|\n",
      "|Charlie|  22|         7|       6914|\n",
      "|  David|  35|        12|       8108|\n",
      "|   Emma|  28|         9|       5268|\n",
      "|  Grace|  23|         3|       6035|\n",
      "|  Henry|  32|        14|       7443|\n",
      "|  Irene|NULL|        25|       9129|\n",
      "|   Jack|  33|      NULL|       NULL|\n",
      "|  Karen|  26|         3|       6901|\n",
      "|    Leo|  29|         1|       5013|\n",
      "|   NULL|  31|         0|       2893|\n",
      "| Nathan|  37|      NULL|       5647|\n",
      "|   NULL|  24|         3|       7004|\n",
      "|   Paul|  38|         1|       7891|\n",
      "|  Quinn|  21|        14|       8890|\n",
      "| Rachel|  34|         3|       1872|\n",
      "|    Sam|NULL|         6|       4916|\n",
      "| Taylor|  36|      NULL|       5554|\n",
      "|   NULL|  42|         7|       2574|\n",
      "+-------+----+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold of only TWO null value\n",
    "df_pyspark.na.drop(how = 'any' , thresh = 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67dd482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+-----------+\n",
      "|    Name| Age|Experience|Salary(USD)|\n",
      "+--------+----+----------+-----------+\n",
      "|   Alice|  25|         2|       1882|\n",
      "|     Bob|  30|         4|       6503|\n",
      "| Charlie|  22|         7|       6914|\n",
      "|   David|  35|        12|       8108|\n",
      "|    Emma|  28|         9|       5268|\n",
      "|   Grace|  23|         3|       6035|\n",
      "|   Henry|  32|        14|       7443|\n",
      "|   Irene|NULL|        25|       9129|\n",
      "|   Karen|  26|         3|       6901|\n",
      "|     Leo|  29|         1|       5013|\n",
      "|    NULL|  31|         0|       2893|\n",
      "|  Nathan|  37|      NULL|       5647|\n",
      "|    NULL|  24|         3|       7004|\n",
      "|    Paul|  38|         1|       7891|\n",
      "|   Quinn|  21|        14|       8890|\n",
      "|  Rachel|  34|         3|       1872|\n",
      "|     Sam|NULL|         6|       4916|\n",
      "|  Taylor|  36|      NULL|       5554|\n",
      "|    NULL|  42|         7|       2574|\n",
      "|Victoria|  20|         6|       6827|\n",
      "+--------+----+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold of only THREE null value\n",
    "df_pyspark.na.drop(how = 'any' , thresh = 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5630f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+-----------+\n",
      "|    Name| Age|Experience|Salary(USD)|\n",
      "+--------+----+----------+-----------+\n",
      "|   Alice|  25|         2|       1882|\n",
      "|     Bob|  30|         4|       6503|\n",
      "| Charlie|  22|         7|       6914|\n",
      "|   David|  35|        12|       8108|\n",
      "|    Emma|  28|         9|       5268|\n",
      "|   Grace|  23|         3|       6035|\n",
      "|   Henry|  32|        14|       7443|\n",
      "|   Irene|NULL|        25|       9129|\n",
      "|   Karen|  26|         3|       6901|\n",
      "|     Leo|  29|         1|       5013|\n",
      "|    NULL|  31|         0|       2893|\n",
      "|    NULL|  24|         3|       7004|\n",
      "|    Paul|  38|         1|       7891|\n",
      "|   Quinn|  21|        14|       8890|\n",
      "|  Rachel|  34|         3|       1872|\n",
      "|     Sam|NULL|         6|       4916|\n",
      "|    NULL|  42|         7|       2574|\n",
      "|Victoria|  20|         6|       6827|\n",
      "|  Walter|NULL|         5|       4873|\n",
      "|  Xander|  28|         2|       7977|\n",
      "+--------+----+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To drop according to a subset\n",
    "df_pyspark.na.drop(how = 'any', subset = ['Experience']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69527fd3",
   "metadata": {},
   "source": [
    "## Filling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71acab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+\n",
      "|   Name| Age|Experience|Salary(USD)|\n",
      "+-------+----+----------+-----------+\n",
      "|  Alice|  25|         2|       1882|\n",
      "|    Bob|  30|         4|       6503|\n",
      "|Charlie|  22|         7|       6914|\n",
      "|  David|  35|        12|       8108|\n",
      "|   Emma|  28|         9|       5268|\n",
      "|  Frank|NULL|      NULL|       NULL|\n",
      "|  Grace|  23|         3|       6035|\n",
      "|  Henry|  32|        14|       7443|\n",
      "|  Irene|NULL|        25|       9129|\n",
      "|   Jack|  33|      NULL|       NULL|\n",
      "|  Karen|  26|         3|       6901|\n",
      "|    Leo|  29|         1|       5013|\n",
      "|   NULL|  31|         0|       2893|\n",
      "| Nathan|  37|      NULL|       5647|\n",
      "|   NULL|  24|         3|       7004|\n",
      "|   Paul|  38|         1|       7891|\n",
      "|  Quinn|  21|        14|       8890|\n",
      "| Rachel|  34|         3|       1872|\n",
      "|    Sam|NULL|         6|       4916|\n",
      "| Taylor|  36|      NULL|       5554|\n",
      "+-------+----+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('Missing Values', ['Experience' , 'Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#42:45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc8987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
