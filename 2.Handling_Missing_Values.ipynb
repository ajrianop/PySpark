{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ecddeb",
   "metadata": {},
   "source": [
    "# Handling with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7afa1a7",
   "metadata": {},
   "source": [
    "Let us read the csv file, with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe4305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Missing_values').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df37b493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|   Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|  Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|    Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|  David|  35|        12|       7993|  NULL|                NULL|\n",
      "|   Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|  Frank|NULL|      NULL|       NULL|     1|   Software Engineer|\n",
      "|  Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|  Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|  Irene|NULL|        25|       2896|  NULL|                NULL|\n",
      "|   Jack|  33|      NULL|       NULL|     9|    Graphic Designer|\n",
      "|  Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|    Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|   NULL|  31|         0|       2706|     5|   Marketing Manager|\n",
      "| Nathan|  37|      NULL|       6894|     2|      Data Scientist|\n",
      "|   NULL|  24|         3|       6806|     2|      Data Scientist|\n",
      "|   Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|  Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "| Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|    Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "| Taylor|  36|      NULL|       4320|     3|     Project Manager|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the file with missing values\n",
    "df_pyspark = spark.read.csv('data/names_and_ages_missing_val.csv', header = True , inferSchema = True , sep = ';')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5ddbf",
   "metadata": {},
   "source": [
    "## Using the method .drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280fc30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------+------+--------------------+\n",
      "|    Name|Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+--------+---+----------+-----------+------+--------------------+\n",
      "|   Alice| 25|         2|       9666|     3|     Project Manager|\n",
      "|     Bob| 30|         4|       7226|     5|   Marketing Manager|\n",
      "| Charlie| 22|         7|       7484|    10|  Operations Manager|\n",
      "|    Emma| 28|         9|       3170|     8|Customer Service ...|\n",
      "|   Grace| 23|         3|       4815|     8|Customer Service ...|\n",
      "|   Henry| 32|        14|       8611|     9|    Graphic Designer|\n",
      "|   Karen| 26|         3|       5347|     6|   Financial Analyst|\n",
      "|     Leo| 29|         1|       6668|     4|     Sales Associate|\n",
      "|    Paul| 38|         1|       3162|     1|   Software Engineer|\n",
      "|   Quinn| 21|        14|       8665|     5|   Marketing Manager|\n",
      "|  Rachel| 34|         3|       5624|     8|Customer Service ...|\n",
      "|Victoria| 20|         6|       1763|     8|Customer Service ...|\n",
      "|  Xander| 28|         2|       4330|     1|   Software Engineer|\n",
      "| Yasmine| 31|         8|       2379|     8|Customer Service ...|\n",
      "| Zachary| 29|         2|       5741|    10|  Operations Manager|\n",
      "|     Ava| 26|         4|       7638|     8|Customer Service ...|\n",
      "|Benjamin| 32|         3|       8346|     8|Customer Service ...|\n",
      "|   Chloe| 23|         6|       7151|     7|Human Resources S...|\n",
      "|  Daniel| 35|        21|       3856|     8|Customer Service ...|\n",
      "|   Emily| 27|         0|       7092|     1|   Software Engineer|\n",
      "+--------+---+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows with NULL values\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10eaa61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|   Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|  Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|    Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|  David|  35|        12|       7993|  NULL|                NULL|\n",
      "|   Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|  Frank|NULL|      NULL|       NULL|     1|   Software Engineer|\n",
      "|  Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|  Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|  Irene|NULL|        25|       2896|  NULL|                NULL|\n",
      "|   Jack|  33|      NULL|       NULL|     9|    Graphic Designer|\n",
      "|  Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|    Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|   NULL|  31|         0|       2706|     5|   Marketing Manager|\n",
      "| Nathan|  37|      NULL|       6894|     2|      Data Scientist|\n",
      "|   NULL|  24|         3|       6806|     2|      Data Scientist|\n",
      "|   Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|  Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "| Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|    Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "| Taylor|  36|      NULL|       4320|     3|     Project Manager|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To drop all the columns which has NULL values in all the line,\n",
    "# but this command doesn't drop the rows with one, two or three null entries\n",
    "# in the same line\n",
    "df_pyspark.na.drop(how = 'all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52347e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------+------+--------------------+\n",
      "|    Name|Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+--------+---+----------+-----------+------+--------------------+\n",
      "|   Alice| 25|         2|       9666|     3|     Project Manager|\n",
      "|     Bob| 30|         4|       7226|     5|   Marketing Manager|\n",
      "| Charlie| 22|         7|       7484|    10|  Operations Manager|\n",
      "|    Emma| 28|         9|       3170|     8|Customer Service ...|\n",
      "|   Grace| 23|         3|       4815|     8|Customer Service ...|\n",
      "|   Henry| 32|        14|       8611|     9|    Graphic Designer|\n",
      "|   Karen| 26|         3|       5347|     6|   Financial Analyst|\n",
      "|     Leo| 29|         1|       6668|     4|     Sales Associate|\n",
      "|    Paul| 38|         1|       3162|     1|   Software Engineer|\n",
      "|   Quinn| 21|        14|       8665|     5|   Marketing Manager|\n",
      "|  Rachel| 34|         3|       5624|     8|Customer Service ...|\n",
      "|Victoria| 20|         6|       1763|     8|Customer Service ...|\n",
      "|  Xander| 28|         2|       4330|     1|   Software Engineer|\n",
      "| Yasmine| 31|         8|       2379|     8|Customer Service ...|\n",
      "| Zachary| 29|         2|       5741|    10|  Operations Manager|\n",
      "|     Ava| 26|         4|       7638|     8|Customer Service ...|\n",
      "|Benjamin| 32|         3|       8346|     8|Customer Service ...|\n",
      "|   Chloe| 23|         6|       7151|     7|Human Resources S...|\n",
      "|  Daniel| 35|        21|       3856|     8|Customer Service ...|\n",
      "|   Emily| 27|         0|       7092|     1|   Software Engineer|\n",
      "+--------+---+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To drop all the columns which contains at least one NULL value in the line\n",
    "df_pyspark.na.drop(how = 'any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f68c7289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|   Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|  Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|    Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|  David|  35|        12|       7993|  NULL|                NULL|\n",
      "|   Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|  Frank|NULL|      NULL|       NULL|     1|   Software Engineer|\n",
      "|  Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|  Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|  Irene|NULL|        25|       2896|  NULL|                NULL|\n",
      "|   Jack|  33|      NULL|       NULL|     9|    Graphic Designer|\n",
      "|  Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|    Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|   NULL|  31|         0|       2706|     5|   Marketing Manager|\n",
      "| Nathan|  37|      NULL|       6894|     2|      Data Scientist|\n",
      "|   NULL|  24|         3|       6806|     2|      Data Scientist|\n",
      "|   Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|  Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "| Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|    Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "| Taylor|  36|      NULL|       4320|     3|     Project Manager|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold of only ONE null value\n",
    "df_pyspark.na.drop(how = 'any' , thresh = 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78297457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|   Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|  Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|    Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|  David|  35|        12|       7993|  NULL|                NULL|\n",
      "|   Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|  Frank|NULL|      NULL|       NULL|     1|   Software Engineer|\n",
      "|  Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|  Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|  Irene|NULL|        25|       2896|  NULL|                NULL|\n",
      "|   Jack|  33|      NULL|       NULL|     9|    Graphic Designer|\n",
      "|  Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|    Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|   NULL|  31|         0|       2706|     5|   Marketing Manager|\n",
      "| Nathan|  37|      NULL|       6894|     2|      Data Scientist|\n",
      "|   NULL|  24|         3|       6806|     2|      Data Scientist|\n",
      "|   Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|  Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "| Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|    Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "| Taylor|  36|      NULL|       4320|     3|     Project Manager|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold of only TWO null value\n",
    "df_pyspark.na.drop(how = 'any' , thresh = 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67dd482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|   Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|  Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|    Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|  David|  35|        12|       7993|  NULL|                NULL|\n",
      "|   Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|  Frank|NULL|      NULL|       NULL|     1|   Software Engineer|\n",
      "|  Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|  Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|  Irene|NULL|        25|       2896|  NULL|                NULL|\n",
      "|   Jack|  33|      NULL|       NULL|     9|    Graphic Designer|\n",
      "|  Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|    Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|   NULL|  31|         0|       2706|     5|   Marketing Manager|\n",
      "| Nathan|  37|      NULL|       6894|     2|      Data Scientist|\n",
      "|   NULL|  24|         3|       6806|     2|      Data Scientist|\n",
      "|   Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|  Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "| Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|    Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "| Taylor|  36|      NULL|       4320|     3|     Project Manager|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold of only THREE null value\n",
    "df_pyspark.na.drop(how = 'any' , thresh = 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5630f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+-----------+------+--------------------+\n",
      "|    Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+--------+----+----------+-----------+------+--------------------+\n",
      "|   Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|     Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "| Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|   David|  35|        12|       7993|  NULL|                NULL|\n",
      "|    Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|   Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|   Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|   Irene|NULL|        25|       2896|  NULL|                NULL|\n",
      "|   Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|     Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|    NULL|  31|         0|       2706|     5|   Marketing Manager|\n",
      "|    NULL|  24|         3|       6806|     2|      Data Scientist|\n",
      "|    Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|   Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "|  Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|     Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "|    NULL|  42|         7|       2337|     6|   Financial Analyst|\n",
      "|Victoria|  20|         6|       1763|     8|Customer Service ...|\n",
      "|  Walter|NULL|         5|       5237|     2|      Data Scientist|\n",
      "|  Xander|  28|         2|       4330|     1|   Software Engineer|\n",
      "+--------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To drop according to a subset\n",
    "df_pyspark.na.drop(how = 'any', subset = ['Experience']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69527fd3",
   "metadata": {},
   "source": [
    "## Filling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280ef6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'),\n",
       " ('Age', 'int'),\n",
       " ('Experience', 'int'),\n",
       " ('Salary(USD)', 'int'),\n",
       " ('ID job', 'int'),\n",
       " ('Current Position', 'string')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca51f4a0",
   "metadata": {},
   "source": [
    "If we desire to filleach NULL value we can use the function .na.fill(missin_value), note that the type of the variable missing value play a relevant role to fill in, as the next cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3e82e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+-----------+------+--------------------+\n",
      "|          Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+--------------+----+----------+-----------+------+--------------------+\n",
      "|         Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|           Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|       Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|         David|  35|        12|       7993|  NULL|      Missing Values|\n",
      "|          Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|         Frank|NULL|      NULL|       NULL|     1|   Software Engineer|\n",
      "|         Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|         Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|         Irene|NULL|        25|       2896|  NULL|      Missing Values|\n",
      "|          Jack|  33|      NULL|       NULL|     9|    Graphic Designer|\n",
      "|         Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|           Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|Missing Values|  31|         0|       2706|     5|   Marketing Manager|\n",
      "|        Nathan|  37|      NULL|       6894|     2|      Data Scientist|\n",
      "|Missing Values|  24|         3|       6806|     2|      Data Scientist|\n",
      "|          Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|         Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "|        Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|           Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "|        Taylor|  36|      NULL|       4320|     3|     Project Manager|\n",
      "+--------------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling all the NULL values of type string\n",
    "missing_value = 'Missing Values'\n",
    "df_pyspark.na.fill(missing_value).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "528f463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+-----------+------+--------------------+\n",
      "|   Name|  Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+-------+-----+----------+-----------+------+--------------------+\n",
      "|  Alice|   25|         2|       9666|     3|     Project Manager|\n",
      "|    Bob|   30|         4|       7226|     5|   Marketing Manager|\n",
      "|Charlie|   22|         7|       7484|    10|  Operations Manager|\n",
      "|  David|   35|        12|       7993| 10000|                NULL|\n",
      "|   Emma|   28|         9|       3170|     8|Customer Service ...|\n",
      "|  Frank|10000|     10000|      10000|     1|   Software Engineer|\n",
      "|  Grace|   23|         3|       4815|     8|Customer Service ...|\n",
      "|  Henry|   32|        14|       8611|     9|    Graphic Designer|\n",
      "|  Irene|10000|        25|       2896| 10000|                NULL|\n",
      "|   Jack|   33|     10000|      10000|     9|    Graphic Designer|\n",
      "|  Karen|   26|         3|       5347|     6|   Financial Analyst|\n",
      "|    Leo|   29|         1|       6668|     4|     Sales Associate|\n",
      "|   NULL|   31|         0|       2706|     5|   Marketing Manager|\n",
      "| Nathan|   37|     10000|       6894|     2|      Data Scientist|\n",
      "|   NULL|   24|         3|       6806|     2|      Data Scientist|\n",
      "|   Paul|   38|         1|       3162|     1|   Software Engineer|\n",
      "|  Quinn|   21|        14|       8665|     5|   Marketing Manager|\n",
      "| Rachel|   34|         3|       5624|     8|Customer Service ...|\n",
      "|    Sam|10000|         6|       4723|    10|  Operations Manager|\n",
      "| Taylor|   36|     10000|       4320|     3|     Project Manager|\n",
      "+-------+-----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling all the NULL values of type int (or any type of number according to type)\n",
    "missing_value = 10000\n",
    "df_pyspark.na.fill(missing_value).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e84f92",
   "metadata": {},
   "source": [
    "We also could fill several columns at the same time with a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53cfe606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+-----------+------+--------------------+\n",
      "|          Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+--------------+----+----------+-----------+------+--------------------+\n",
      "|         Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|           Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|       Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|         David|  35|        12|       7993|  NULL|      Missing Values|\n",
      "|          Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|         Frank|NULL|      NULL|       NULL|     1|   Software Engineer|\n",
      "|         Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|         Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|         Irene|NULL|        25|       2896|  NULL|      Missing Values|\n",
      "|          Jack|  33|      NULL|       NULL|     9|    Graphic Designer|\n",
      "|         Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|           Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|Missing Values|  31|         0|       2706|     5|   Marketing Manager|\n",
      "|        Nathan|  37|      NULL|       6894|     2|      Data Scientist|\n",
      "|Missing Values|  24|         3|       6806|     2|      Data Scientist|\n",
      "|          Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|         Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "|        Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|           Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "|        Taylor|  36|      NULL|       4320|     3|     Project Manager|\n",
      "+--------------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling several NULL values in two columns as 'Experience' , 'Salary(USD)' of type string\n",
    "df_pyspark.na.fill('Missing Values', ['Name' , 'Current Position']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71acab32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|   Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|  Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|    Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|  David|  35|        12|       7993|  NULL|                NULL|\n",
      "|   Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|  Frank|NULL|         0|          0|     1|   Software Engineer|\n",
      "|  Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|  Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|  Irene|NULL|        25|       2896|  NULL|                NULL|\n",
      "|   Jack|  33|         0|          0|     9|    Graphic Designer|\n",
      "|  Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|    Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|   NULL|  31|         0|       2706|     5|   Marketing Manager|\n",
      "| Nathan|  37|         0|       6894|     2|      Data Scientist|\n",
      "|   NULL|  24|         3|       6806|     2|      Data Scientist|\n",
      "|   Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|  Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "| Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|    Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "| Taylor|  36|         0|       4320|     3|     Project Manager|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling several NULL values in two columns as 'Experience' , 'Salary(USD)' of type int\n",
    "df_pyspark.na.fill(0, ['Experience' , 'Salary(USD)']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed5cfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|   Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "|  Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|    Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|  David|  35|        12|       7993|  NULL|                NULL|\n",
      "|   Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|  Frank|NULL|      NULL|       NULL|     1|   Software Engineer|\n",
      "|  Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|  Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|  Irene|NULL|        25|       2896|  NULL|                NULL|\n",
      "|   Jack|  33|      NULL|       NULL|     9|    Graphic Designer|\n",
      "|  Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|    Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|   NULL|  31|         0|       2706|     5|   Marketing Manager|\n",
      "| Nathan|  37|      NULL|       6894|     2|      Data Scientist|\n",
      "|   NULL|  24|         3|       6806|     2|      Data Scientist|\n",
      "|   Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|  Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "| Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|    Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "| Taylor|  36|      NULL|       4320|     3|     Project Manager|\n",
      "+-------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.fillna({'Age': '123a'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6cb302",
   "metadata": {},
   "source": [
    "We also coul use the function .fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03fc8987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+-----------+------+--------------------+\n",
      "|          Name| Age|Experience|Salary(USD)|ID job|    Current Position|\n",
      "+--------------+----+----------+-----------+------+--------------------+\n",
      "|         Alice|  25|         2|       9666|     3|     Project Manager|\n",
      "|           Bob|  30|         4|       7226|     5|   Marketing Manager|\n",
      "|       Charlie|  22|         7|       7484|    10|  Operations Manager|\n",
      "|         David|  35|        12|       7993|  NULL|                NULL|\n",
      "|          Emma|  28|         9|       3170|     8|Customer Service ...|\n",
      "|         Frank|NULL|         0|       NULL|     1|   Software Engineer|\n",
      "|         Grace|  23|         3|       4815|     8|Customer Service ...|\n",
      "|         Henry|  32|        14|       8611|     9|    Graphic Designer|\n",
      "|         Irene|NULL|        25|       2896|  NULL|                NULL|\n",
      "|          Jack|  33|         0|       NULL|     9|    Graphic Designer|\n",
      "|         Karen|  26|         3|       5347|     6|   Financial Analyst|\n",
      "|           Leo|  29|         1|       6668|     4|     Sales Associate|\n",
      "|Missing Values|  31|         0|       2706|     5|   Marketing Manager|\n",
      "|        Nathan|  37|         0|       6894|     2|      Data Scientist|\n",
      "|Missing Values|  24|         3|       6806|     2|      Data Scientist|\n",
      "|          Paul|  38|         1|       3162|     1|   Software Engineer|\n",
      "|         Quinn|  21|        14|       8665|     5|   Marketing Manager|\n",
      "|        Rachel|  34|         3|       5624|     8|Customer Service ...|\n",
      "|           Sam|NULL|         6|       4723|    10|  Operations Manager|\n",
      "|        Taylor|  36|         0|       4320|     3|     Project Manager|\n",
      "+--------------+----+----------+-----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill null values in a specific column\n",
    "df_pyspark.fillna({\"Name\": 'Missing Values', 'Experience': 0}).show()  # Fill null values in the 'Age' column with 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66393764",
   "metadata": {},
   "source": [
    "## Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb608de3",
   "metadata": {},
   "source": [
    "The `Imputer` class is used for imputing missing values in DataFrame columns. Imputation is the process of replacing missing values with substituted values, typically based on statistical measures such as mean, median, or mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bba793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols = ['Age' , 'Experience' , 'Salary(USD)'],\n",
    "    outputCols = ['{}_imputed'.format(c) for c in ['age', 'Experience' , 'Salary(USD)']]\n",
    "    ). setStrategy('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d62d353",
   "metadata": {},
   "source": [
    "Usin the imputer class we can create new columns with the mean of each number column that we write in the Imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a93892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-----------+------+--------------------+-----------+------------------+-------------------+\n",
      "|   Name| Age|Experience|Salary(USD)|ID job|    Current Position|age_imputed|Experience_imputed|Salary(USD)_imputed|\n",
      "+-------+----+----------+-----------+------+--------------------+-----------+------------------+-------------------+\n",
      "|  Alice|  25|         2|       9666|     3|     Project Manager|         25|                 2|               9666|\n",
      "|    Bob|  30|         4|       7226|     5|   Marketing Manager|         30|                 4|               7226|\n",
      "|Charlie|  22|         7|       7484|    10|  Operations Manager|         22|                 7|               7484|\n",
      "|  David|  35|        12|       7993|  NULL|                NULL|         35|                12|               7993|\n",
      "|   Emma|  28|         9|       3170|     8|Customer Service ...|         28|                 9|               3170|\n",
      "|  Frank|NULL|      NULL|       NULL|     1|   Software Engineer|         30|                 7|               5365|\n",
      "|  Grace|  23|         3|       4815|     8|Customer Service ...|         23|                 3|               4815|\n",
      "|  Henry|  32|        14|       8611|     9|    Graphic Designer|         32|                14|               8611|\n",
      "|  Irene|NULL|        25|       2896|  NULL|                NULL|         30|                25|               2896|\n",
      "|   Jack|  33|      NULL|       NULL|     9|    Graphic Designer|         33|                 7|               5365|\n",
      "|  Karen|  26|         3|       5347|     6|   Financial Analyst|         26|                 3|               5347|\n",
      "|    Leo|  29|         1|       6668|     4|     Sales Associate|         29|                 1|               6668|\n",
      "|   NULL|  31|         0|       2706|     5|   Marketing Manager|         31|                 0|               2706|\n",
      "| Nathan|  37|      NULL|       6894|     2|      Data Scientist|         37|                 7|               6894|\n",
      "|   NULL|  24|         3|       6806|     2|      Data Scientist|         24|                 3|               6806|\n",
      "|   Paul|  38|         1|       3162|     1|   Software Engineer|         38|                 1|               3162|\n",
      "|  Quinn|  21|        14|       8665|     5|   Marketing Manager|         21|                14|               8665|\n",
      "| Rachel|  34|         3|       5624|     8|Customer Service ...|         34|                 3|               5624|\n",
      "|    Sam|NULL|         6|       4723|    10|  Operations Manager|         30|                 6|               4723|\n",
      "| Taylor|  36|      NULL|       4320|     3|     Project Manager|         36|                 7|               4320|\n",
      "+-------+----+----------+-----------+------+--------------------+-----------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To add imputation cols to df_pyspark we fit the\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61310941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ebdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43d9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5deab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
